# Getting and Cleaning data on Coursera Data Science Courses
# Quiz2 study note
# Question 1

library(httr)
require(httpuv)
require(jsonlite)

oauth_endpoints("github")

myapp <- oauth_app("github", "38e093d472d919cf750a","e54e15d23251c09c2056389eec8ac93cb20ddfaf")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp) # need authorize the permission on popup menu
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[5]]$name, output[[5]]$created_at)
===================================
# Question 2
install.packages("RMySQL")
install.packages("sqldf")

# Since the following error msgs listed as follow are shown, 
# Error in mysqlNewConnection(drv, ...) : RS-DBI driver: (Failed to connect to database: Error: Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2) )
# Error msg: tcltk package being missing

# Two additional settings are attched 
options(sqldf.driver = "SQLite") # as per FAQ #7 force SQLite
options(gsubfn.engine = "R") # as per FAQ #5 use R code rather than tcltk
# reference link 1: http://stackoverflow.com/questions/8219747/sqldf-package-in-r-querying-a-data-frame
# reference link 2: https://code.google.com/p/sqldf/

library(RMySQL)
library(sqldf)

url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, destfile=f, method="curl") # need specify method="curl"for my mac OS
acs <- read.csv("ss06pid.csv")
acs <- data.table(read.csv(f)) # data.table() and data.frame both work in this case. 
sqldf("select pwgtp1 from acs where AGEP < 50") 
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
# str(query1)
# 'data.frame':    10093 obs. of  1 variable:
#$ pwgtp1: int  87 88 94 91 539 192 153 232 205 226 ...

query2 <- sqldf("select pwgtp1 from acs")
# str(query2)
# 'data.frame':    14931 obs. of  1 variable:
# $ pwgtp1: int  87 88 94 91 539 192 153 232 205 226 ...
 
query3 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")
query4 <- sqldf("select * from acs where AGEP < 50")
identical(query3, query4)
# [1] TRUE
# str(query3)
# 'data.frame':    10093 obs. of  239 variables:
# $ RT      : Factor w/ 1 level "P": 1 1 1 1 1 1 1 1 1 1 ...
# $ SERIALNO: int  186 186 186 186 306 395 395 506 506 506 ...
# ......

#NOTE:
#query1, query2, query3 and query4 are all right form of syntax, but only query1 would get the right answer for the question we are interested in.
#

=============================================
# Question 3

# unique(acs$AGEP)
# [1] 43 42 16 14 29 40 15 28 30  4  1 18 37 39  3 87 70 49 45
# [20] 50 60 59 61 64 35 12 19 31  9  0 33 32 20 88 53 58 69 68
# [39] 48 24 27 74 56 75 17 38 55 26 23 86 81 77  7 51 13 11 82
# [58] 47 46 80 21 54 78 67 22  2 76  6 71 34 10  5 65 62 63 57
# [77] 52 79 83 66 25 93  8 36 41 44 84 72 73 85 89
    
#  query1 <- sqldf("select unique AGEP from acs")
# Error in sqliteSendQuery(con, statement, bind.data) : 
#     error in statement: near "unique": syntax error

#  query2 <- sqldf("select AGEP where unique from acs")
# Error in sqliteSendQuery(con, statement, bind.data) : 
#     error in statement: near "unique": syntax error

#  query3 <- sqldf("select distinct AGEP from acs")
#  query4 <- sqldf("select distinct pwgtp1 from acs")

==============================
# Question 4
 
con <- url("http://biostat.jhsph.edu/~jleek/contact.html") 
htmllines <- readLines(con)
close(con)

# check the structure of htmllines
# str(htmllines)
# chr [1:180] "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">" ...

# head(htmllines)
# [1] "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">"
# [2] ""  

# > nchar(htmllines[10])
# [1] 45
# > nchar(htmllines[20])
# [1] 31
# > nchar(htmllines[30])
# [1] 7
# > nchar(htmllines[100])
# [1] 25


=====================================================================
# Question 5
install.packages("XML")
library(XML)

url2 <- "http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"

f2 <- file.path(getwd(), "WeeklySST.txt")
download.file(url2, destfile=f2, method="curl")
# read.fwf(file, widths, header = FALSE, sep = "\t",
# skip = 0, row.names, col.names, n = -1,
# buffersize = 2000, ...)
data <-read.fwf("WeeklySST.txt", widths=c(14,5,8,5,8,5,8,5,8), header = FALSE, skip=4)
sum(data[,4])
